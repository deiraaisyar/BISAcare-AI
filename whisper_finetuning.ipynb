{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745304f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/lenovo/anaconda3/lib/python3.12/site-packages (25.2)\n",
      "Requirement already satisfied: transformers in /home/lenovo/anaconda3/lib/python3.12/site-packages (4.51.2)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.55.2-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting jiwer\n",
      "  Using cached jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting tensorboard\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gradio\n",
      "  Using cached gradio-5.42.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting datasets[audio]\n",
      "  Using cached datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /home/lenovo/anaconda3/lib/python3.12/site-packages (from datasets[audio]) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from datasets[audio]) (1.26.4)\n",
      "Collecting pyarrow>=15.0.0 (from datasets[audio])\n",
      "  Using cached pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets[audio])\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /home/lenovo/anaconda3/lib/python3.12/site-packages (from datasets[audio]) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from datasets[audio]) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from datasets[audio]) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/lenovo/anaconda3/lib/python3.12/site-packages (from datasets[audio]) (3.5.0)\n",
      "Collecting multiprocess<0.70.17 (from datasets[audio])\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from datasets[audio]) (0.30.2)\n",
      "Requirement already satisfied: packaging in /home/lenovo/anaconda3/lib/python3.12/site-packages (from datasets[audio]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from datasets[audio]) (6.0.1)\n",
      "Collecting soundfile>=0.12.1 (from datasets[audio])\n",
      "  Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting torchcodec>=0.4.0 (from datasets[audio])\n",
      "  Using cached torchcodec-0.6.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting torch>=2.7.0 (from datasets[audio])\n",
      "  Using cached torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (3.9.5)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets[audio])\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets[audio]) (4.14.1)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.24.0->datasets[audio])\n",
      "  Using cached hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (703 bytes)\n",
      "Requirement already satisfied: psutil in /home/lenovo/anaconda3/lib/python3.12/site-packages (from accelerate) (5.9.0)\n",
      "Collecting click>=8.1.8 (from jiwer)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
      "  Using cached rapidfuzz-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from tensorboard) (1.73.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: pillow in /home/lenovo/anaconda3/lib/python3.12/site-packages (from tensorboard) (10.3.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from tensorboard) (6.31.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from tensorboard) (69.5.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from tensorboard) (3.1.3)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from gradio) (4.2.0)\n",
      "Collecting brotli>=1.1.0 (from gradio)\n",
      "  Using cached Brotli-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from gradio) (0.115.9)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Using cached ffmpy-0.6.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.11.1 (from gradio)\n",
      "  Using cached gradio_client-1.11.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Using cached groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from gradio) (3.10.12)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from gradio) (2.5.3)\n",
      "Collecting pydub (from gradio)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Using cached ruff-0.12.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Using cached safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from gradio) (0.45.3)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Using cached tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from gradio) (0.15.4)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from gradio) (0.34.2)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from gradio-client==1.11.1->gradio) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in /home/lenovo/anaconda3/lib/python3.12/site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/lenovo/anaconda3/lib/python3.12/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from pandas->datasets[audio]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from pandas->datasets[audio]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from pandas->datasets[audio]) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from pydantic<2.12,>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from pydantic<2.12,>=2.0->gradio) (2.14.6)\n",
      "Collecting click>=8.1.8 (from jiwer)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (13.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (1.9.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets[audio]) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets[audio]) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets[audio]) (2.5.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from soundfile>=0.12.1->datasets[audio]) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/lenovo/anaconda3/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (2.21)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.7.0->datasets[audio])\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /home/lenovo/anaconda3/lib/python3.12/site-packages (from torch>=2.7.0->datasets[audio]) (3.2.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.7.0->datasets[audio])\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.7.0->datasets[audio])\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.7.0->datasets[audio])\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.7.0->datasets[audio])\n",
      "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.7.0->datasets[audio])\n",
      "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.7.0->datasets[audio])\n",
      "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.7.0->datasets[audio])\n",
      "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.7.0->datasets[audio])\n",
      "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.7.0->datasets[audio])\n",
      "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.7.0->datasets[audio])\n",
      "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch>=2.7.0->datasets[audio])\n",
      "  Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.7.0->datasets[audio])\n",
      "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.7.0->datasets[audio])\n",
      "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.7.0->datasets[audio])\n",
      "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.4.0 (from torch>=2.7.0->datasets[audio])\n",
      "  Using cached triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/lenovo/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.7.0->datasets[audio]) (1.3.0)\n",
      "Using cached datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached transformers-4.55.2-py3-none-any.whl (11.3 MB)\n",
      "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Using cached hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Using cached accelerate-1.10.0-py3-none-any.whl (374 kB)\n",
      "Using cached evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
      "Using cached jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Using cached gradio-5.42.0-py3-none-any.whl (59.7 MB)\n",
      "Using cached gradio_client-1.11.1-py3-none-any.whl (324 kB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Using cached safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Using cached tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached Brotli-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "Using cached pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Using cached rapidfuzz-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached ruff-0.12.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "Using cached torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
      "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Using cached triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached torchcodec-0.6.0-cp312-cp312-manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "Using cached ffmpy-0.6.1-py3-none-any.whl (5.5 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub, nvidia-cusparselt-cu12, brotli, triton, torchcodec, tomlkit, tensorboard-data-server, sympy, semantic-version, ruff, rapidfuzz, python-multipart, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf-xet, groovy, ffmpy, dill, click, aiofiles, absl-py, tensorboard, soundfile, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, jiwer, huggingface-hub, safehttpx, nvidia-cusolver-cu12, gradio-client, transformers, torch, gradio, datasets, evaluate, accelerate\n",
      "\u001b[2K  Attempting uninstall: brotli━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/46\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Found existing installation: Brotli 1.0.9━━━━━━━━\u001b[0m \u001b[32m 1/46\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Uninstalling Brotli-1.0.9:━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/46\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K      Successfully uninstalled Brotli-1.0.9━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/46\u001b[0m [brotli]12]\n",
      "\u001b[2K  Attempting uninstall: triton━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/46\u001b[0m [brotli]\n",
      "\u001b[2K    Found existing installation: triton 3.2.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/46\u001b[0m [brotli]\n",
      "\u001b[2K    Uninstalling triton-3.2.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/46\u001b[0m [brotli]\n",
      "\u001b[2K      Successfully uninstalled triton-3.2.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/46\u001b[0m [brotli]\n",
      "\u001b[2K  Attempting uninstall: tomlkit━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/46\u001b[0m [torchcodec]\n",
      "\u001b[2K    Found existing installation: tomlkit 0.11.1━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/46\u001b[0m [tomlkit]\n",
      "\u001b[2K    Uninstalling tomlkit-0.11.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/46\u001b[0m [tomlkit]\n",
      "\u001b[2K      Successfully uninstalled tomlkit-0.11.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/46\u001b[0m [tomlkit]\n",
      "\u001b[2K  Attempting uninstall: sympy90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/46\u001b[0m [tensorboard-data-server]\n",
      "\u001b[2K    Found existing installation: sympy 1.13.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/46\u001b[0m [tensorboard-data-server]\n",
      "\u001b[2K    Uninstalling sympy-1.13.1:90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/46\u001b[0m [sympy]d-data-server]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.13.1━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/46\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: pyarrow\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/46\u001b[0m [python-multipart]\n",
      "\u001b[2K    Found existing installation: pyarrow 14.0.2━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/46\u001b[0m [python-multipart]\n",
      "\u001b[2K    Uninstalling pyarrow-14.0.2:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/46\u001b[0m [pyarrow]part]\n",
      "\u001b[2K      Successfully uninstalled pyarrow-14.0.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/46\u001b[0m [pyarrow]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/46\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.24.3━━━━━━\u001b[0m \u001b[32m14/46\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.24.3:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/46\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.24.3━━━━━━━━\u001b[0m \u001b[32m14/46\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: dill\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/46\u001b[0m [ffmpy]-cublas-cu12]u12]\n",
      "\u001b[2K    Found existing installation: dill 0.4.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/46\u001b[0m [ffmpy]\n",
      "\u001b[2K    Uninstalling dill-0.4.0:\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/46\u001b[0m [ffmpy]\n",
      "\u001b[2K      Successfully uninstalled dill-0.4.00m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/46\u001b[0m [ffmpy]\n",
      "\u001b[2K  Attempting uninstall: click\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/46\u001b[0m [dill]\n",
      "\u001b[2K    Found existing installation: click 8.1.7━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/46\u001b[0m [dill]\n",
      "\u001b[2K    Uninstalling click-8.1.7:\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/46\u001b[0m [dill]\n",
      "\u001b[2K      Successfully uninstalled click-8.1.70m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/46\u001b[0m [dill]\n",
      "\u001b[2K  Attempting uninstall: multiprocess\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m33/46\u001b[0m [nvidia-cudnn-cu12]12]\n",
      "\u001b[2K    Found existing installation: multiprocess 0.70.18━━━━━━━━━\u001b[0m \u001b[32m33/46\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling multiprocess-0.70.18:[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m34/46\u001b[0m [multiprocess]]\n",
      "\u001b[2K      Successfully uninstalled multiprocess-0.70.18m━━━━━━━━━━\u001b[0m \u001b[32m34/46\u001b[0m [multiprocess]\n",
      "\u001b[2K  Attempting uninstall: huggingface-hub0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m34/46\u001b[0m [multiprocess]\n",
      "\u001b[2K    Found existing installation: huggingface-hub 0.30.2━━━━━━━\u001b[0m \u001b[32m34/46\u001b[0m [multiprocess]\n",
      "\u001b[2K    Uninstalling huggingface-hub-0.30.2:1m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m34/46\u001b[0m [multiprocess]\n",
      "\u001b[2K      Successfully uninstalled huggingface-hub-0.30.2━━━━━━━━━\u001b[0m \u001b[32m34/46\u001b[0m [multiprocess]\n",
      "\u001b[2K  Attempting uninstall: transformers━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m39/46\u001b[0m [gradio-client]r-cu12]\n",
      "\u001b[2K    Found existing installation: transformers 4.51.2[90m━━━━━━\u001b[0m \u001b[32m39/46\u001b[0m [gradio-client]\n",
      "\u001b[2K    Uninstalling transformers-4.51.2:━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m40/46\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.51.20m\u001b[90m━━━━━\u001b[0m \u001b[32m40/46\u001b[0m [transformers]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m40/46\u001b[0m [transformers]\n",
      "\u001b[2K    Found existing installation: torch 2.6.0+cu1180m\u001b[90m━━━━━\u001b[0m \u001b[32m40/46\u001b[0m [transformers]\n",
      "\u001b[2K    Uninstalling torch-2.6.0+cu118:━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m41/46\u001b[0m [torch]rs]\n",
      "\u001b[2K      Successfully uninstalled torch-2.6.0+cu118[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m41/46\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/46\u001b[0m [accelerate]celerate]tasets]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.44.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.44.1 requires protobuf<6,>=3.20, but you have protobuf 6.31.1 which is incompatible.\n",
      "torchvision 0.21.0+cu118 requires torch==2.6.0, but you have torch 2.8.0 which is incompatible.\n",
      "nlp-id 0.1.15.0 requires nltk==3.8.1, but you have nltk 3.9.1 which is incompatible.\n",
      "torchaudio 2.6.0+cu118 requires torch==2.6.0, but you have torch 2.8.0 which is incompatible.\n",
      "pathos 0.3.4 requires dill>=0.4.0, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.4 requires multiprocess>=0.70.18, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-2.3.1 accelerate-1.10.0 aiofiles-24.1.0 brotli-1.1.0 click-8.1.8 datasets-4.0.0 dill-0.3.8 evaluate-0.4.5 ffmpy-0.6.1 gradio-5.42.0 gradio-client-1.11.1 groovy-0.1.2 hf-xet-1.1.7 huggingface-hub-0.34.4 jiwer-4.0.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 pyarrow-21.0.0 pydub-0.25.1 python-multipart-0.0.20 rapidfuzz-3.13.0 ruff-0.12.9 safehttpx-0.1.6 semantic-version-2.10.0 soundfile-0.13.1 sympy-1.14.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tomlkit-0.13.3 torch-2.8.0 torchcodec-0.6.0 transformers-4.55.2 triton-3.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade datasets[audio] transformers accelerate evaluate jiwer tensorboard gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d99583c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import librosa\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "# Load token dari .env\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "login(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e525bc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since mozilla-foundation/common_voice_17_0 couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'id' at /home/lenovo/.cache/huggingface/datasets/mozilla-foundation___common_voice_17_0/id/17.0.0/9d10386a731ff6e6ed4ec973a4dc204a9820e8c842fbe388bdba0dd205ed5016 (last modified on Fri Aug 15 20:46:10 2025).\n",
      "Using the latest cached version of the dataset since mozilla-foundation/common_voice_17_0 couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'id' at /home/lenovo/.cache/huggingface/datasets/mozilla-foundation___common_voice_17_0/id/17.0.0/9d10386a731ff6e6ed4ec973a4dc204a9820e8c842fbe388bdba0dd205ed5016 (last modified on Fri Aug 15 20:46:10 2025).\n",
      "Using the latest cached version of the dataset since mozilla-foundation/common_voice_17_0 couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'id' at /home/lenovo/.cache/huggingface/datasets/mozilla-foundation___common_voice_17_0/id/17.0.0/9d10386a731ff6e6ed4ec973a4dc204a9820e8c842fbe388bdba0dd205ed5016 (last modified on Fri Aug 15 20:46:10 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
      "        num_rows: 4970\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
      "        num_rows: 3349\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
      "        num_rows: 3641\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "\n",
    "common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"id\", split=\"train\")\n",
    "common_voice[\"validation\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"id\", split=\"validation\")\n",
    "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"id\", split=\"test\")\n",
    "\n",
    "print(common_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6694ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice = common_voice.remove_columns(['client_id', 'path', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74b3e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperFeatureExtractor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac4bf30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Indonesian\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8656e5c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not load libtorchcodec. Likely causes:\n          1. FFmpeg is not properly installed in your environment. We support\n             versions 4, 5, 6 and 7.\n          2. The PyTorch version (2.8.0+cu128) is not compatible with\n             this version of TorchCodec. Refer to the version compatibility\n             table:\n             https://github.com/pytorch/torchcodec?tab=readme-ov-file#installing-torchcodec.\n          3. Another runtime dependency; see exceptions below.\n        The following exceptions were raised as we tried to load libtorchcodec:\n        \n[start of libtorchcodec loading traceback]\nFFmpeg version 7: libavutil.so.59: cannot open shared object file: No such file or directory\nFFmpeg version 6: /lib/x86_64-linux-gnu/libpango-1.0.so.0: undefined symbol: g_once_init_leave_pointer\nFFmpeg version 5: libavutil.so.57: cannot open shared object file: No such file or directory\nFFmpeg version 4: libavutil.so.56: cannot open shared object file: No such file or directory\n[end of libtorchcodec loading traceback].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m input_str = \u001b[43mcommon_voice\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33msentence\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      2\u001b[39m labels = tokenizer(input_str).input_ids\n\u001b[32m      3\u001b[39m decoded_with_special = tokenizer.decode(labels, skip_special_tokens=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UGM/Lomba/COMPFEST/NLXOTI-AI/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:2859\u001b[39m, in \u001b[36mDataset.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   2857\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._format_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._format_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33marrow\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpandas\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpolars\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   2858\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m Column(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[32m-> \u001b[39m\u001b[32m2859\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UGM/Lomba/COMPFEST/NLXOTI-AI/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:2841\u001b[39m, in \u001b[36mDataset._getitem\u001b[39m\u001b[34m(self, key, **kwargs)\u001b[39m\n\u001b[32m   2839\u001b[39m formatter = get_formatter(format_type, features=\u001b[38;5;28mself\u001b[39m._info.features, **format_kwargs)\n\u001b[32m   2840\u001b[39m pa_subtable = query_table(\u001b[38;5;28mself\u001b[39m._data, key, indices=\u001b[38;5;28mself\u001b[39m._indices)\n\u001b[32m-> \u001b[39m\u001b[32m2841\u001b[39m formatted_output = \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[32m   2843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2844\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UGM/Lomba/COMPFEST/NLXOTI-AI/.venv/lib/python3.12/site-packages/datasets/formatting/formatting.py:657\u001b[39m, in \u001b[36mformat_table\u001b[39m\u001b[34m(table, key, formatter, format_columns, output_all_columns)\u001b[39m\n\u001b[32m    655\u001b[39m python_formatter = PythonFormatter(features=formatter.features)\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m query_type == \u001b[33m\"\u001b[39m\u001b[33mcolumn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UGM/Lomba/COMPFEST/NLXOTI-AI/.venv/lib/python3.12/site-packages/datasets/formatting/formatting.py:410\u001b[39m, in \u001b[36mFormatter.__call__\u001b[39m\u001b[34m(self, pa_table, query_type)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa.Table, query_type: \u001b[38;5;28mstr\u001b[39m) -> Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[32m    409\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m query_type == \u001b[33m\"\u001b[39m\u001b[33mrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m query_type == \u001b[33m\"\u001b[39m\u001b[33mcolumn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    412\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_column(pa_table)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UGM/Lomba/COMPFEST/NLXOTI-AI/.venv/lib/python3.12/site-packages/datasets/formatting/formatting.py:459\u001b[39m, in \u001b[36mPythonFormatter.format_row\u001b[39m\u001b[34m(self, pa_table)\u001b[39m\n\u001b[32m    457\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    458\u001b[39m row = \u001b[38;5;28mself\u001b[39m.python_arrow_extractor().extract_row(pa_table)\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m row = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpython_features_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UGM/Lomba/COMPFEST/NLXOTI-AI/.venv/lib/python3.12/site-packages/datasets/formatting/formatting.py:223\u001b[39m, in \u001b[36mPythonFeaturesDecoder.decode_row\u001b[39m\u001b[34m(self, row)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: \u001b[38;5;28mdict\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.features \u001b[38;5;28;01melse\u001b[39;00m row\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UGM/Lomba/COMPFEST/NLXOTI-AI/.venv/lib/python3.12/site-packages/datasets/features/features.py:2093\u001b[39m, in \u001b[36mFeatures.decode_example\u001b[39m\u001b[34m(self, example, token_per_repo_id)\u001b[39m\n\u001b[32m   2078\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   2079\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[32m   2080\u001b[39m \n\u001b[32m   2081\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2089\u001b[39m \u001b[33;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[32m   2090\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   2092\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m-> \u001b[39m\u001b[32m2093\u001b[39m         column_name: \u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2094\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._column_requires_decoding[column_name]\n\u001b[32m   2095\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[32m   2096\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[32m   2097\u001b[39m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[32m   2098\u001b[39m         )\n\u001b[32m   2099\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UGM/Lomba/COMPFEST/NLXOTI-AI/.venv/lib/python3.12/site-packages/datasets/features/features.py:1405\u001b[39m, in \u001b[36mdecode_nested_example\u001b[39m\u001b[34m(schema, obj, token_per_repo_id)\u001b[39m\n\u001b[32m   1402\u001b[39m \u001b[38;5;66;03m# Object with special decoding:\u001b[39;00m\n\u001b[32m   1403\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema, \u001b[33m\"\u001b[39m\u001b[33mdecode_example\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[33m\"\u001b[39m\u001b[33mdecode\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1404\u001b[39m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1405\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1406\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UGM/Lomba/COMPFEST/NLXOTI-AI/.venv/lib/python3.12/site-packages/datasets/features/audio.py:170\u001b[39m, in \u001b[36mAudio.decode_example\u001b[39m\u001b[34m(self, value, token_per_repo_id)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Decode example audio file into audio data.\u001b[39;00m\n\u001b[32m    154\u001b[39m \n\u001b[32m    155\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m \u001b[33;03m    `torchcodec.decoders.AudioDecoder`\u001b[39;00m\n\u001b[32m    168\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.TORCHCODEC_AVAILABLE:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_torchcodec\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioDecoder\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTo support decoding audio data, please install \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtorchcodec\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UGM/Lomba/COMPFEST/NLXOTI-AI/.venv/lib/python3.12/site-packages/datasets/features/_torchcodec.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchcodec\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdecoders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioDecoder \u001b[38;5;28;01mas\u001b[39;00m _AudioDecoder\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mAudioDecoder\u001b[39;00m(_AudioDecoder):\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UGM/Lomba/COMPFEST/NLXOTI-AI/.venv/lib/python3.12/site-packages/torchcodec/__init__.py:10\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Note: usort wants to put Frame and FrameBatch after decoders and samplers,\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# but that results in circular import.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_frame\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioSamples, Frame, FrameBatch  \u001b[38;5;66;03m# usort:skip # noqa\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decoders, samplers  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# Note that version.py is generated during install.\u001b[39;00m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UGM/Lomba/COMPFEST/NLXOTI-AI/.venv/lib/python3.12/site-packages/torchcodec/decoders/__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# This source code is licensed under the BSD-style license found in the\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioStreamMetadata, VideoStreamMetadata\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_audio_decoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioDecoder  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_video_decoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VideoDecoder  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UGM/Lomba/COMPFEST/NLXOTI-AI/.venv/lib/python3.12/site-packages/torchcodec/_core/__init__.py:8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# This source code is licensed under the BSD-style license found in the\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_metadata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     AudioStreamMetadata,\n\u001b[32m     10\u001b[39m     ContainerMetadata,\n\u001b[32m     11\u001b[39m     get_container_metadata,\n\u001b[32m     12\u001b[39m     get_container_metadata_from_header,\n\u001b[32m     13\u001b[39m     VideoStreamMetadata,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     _add_video_stream,\n\u001b[32m     17\u001b[39m     _get_key_frame_indices,\n\u001b[32m   (...)\u001b[39m\u001b[32m     38\u001b[39m     seek_to_pts,\n\u001b[32m     39\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UGM/Lomba/COMPFEST/NLXOTI-AI/.venv/lib/python3.12/site-packages/torchcodec/_core/_metadata.py:16\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Optional, Union\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchcodec\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     _get_container_json_metadata,\n\u001b[32m     18\u001b[39m     _get_stream_json_metadata,\n\u001b[32m     19\u001b[39m     create_from_file,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     23\u001b[39m SPACES = \u001b[33m\"\u001b[39m\u001b[33m  \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mStreamMetadata\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UGM/Lomba/COMPFEST/NLXOTI-AI/.venv/lib/python3.12/site-packages/torchcodec/_core/ops.py:84\u001b[39m\n\u001b[32m     64\u001b[39m     traceback = (\n\u001b[32m     65\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[start of libtorchcodec loading traceback]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     66\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFFmpeg version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v, e \u001b[38;5;129;01min\u001b[39;00m exceptions)\n\u001b[32m     67\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[end of libtorchcodec loading traceback].\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     68\u001b[39m     )\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     70\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mCould not load libtorchcodec. Likely causes:\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[33m          1. FFmpeg is not properly installed in your environment. We support\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     81\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m \u001b[43mload_torchcodec_shared_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Note: We use disallow_in_graph because PyTorch does constant propagation of\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# factory functions.\u001b[39;00m\n\u001b[32m     89\u001b[39m create_from_file = torch._dynamo.disallow_in_graph(\n\u001b[32m     90\u001b[39m     torch.ops.torchcodec_ns.create_from_file.default\n\u001b[32m     91\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UGM/Lomba/COMPFEST/NLXOTI-AI/.venv/lib/python3.12/site-packages/torchcodec/_core/ops.py:69\u001b[39m, in \u001b[36mload_torchcodec_shared_libraries\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     62\u001b[39m         exceptions.append((ffmpeg_major_version, e))\n\u001b[32m     64\u001b[39m traceback = (\n\u001b[32m     65\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[start of libtorchcodec loading traceback]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     66\u001b[39m     + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFFmpeg version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v, e \u001b[38;5;129;01min\u001b[39;00m exceptions)\n\u001b[32m     67\u001b[39m     + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[end of libtorchcodec loading traceback].\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     68\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     70\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mCould not load libtorchcodec. Likely causes:\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[33m      1. FFmpeg is not properly installed in your environment. We support\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[33m         versions 4, 5, 6 and 7.\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[33m      2. The PyTorch version (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) is not compatible with\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[33m         this version of TorchCodec. Refer to the version compatibility\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[33m         table:\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[33m         https://github.com/pytorch/torchcodec?tab=readme-ov-file#installing-torchcodec.\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[33m      3. Another runtime dependency; see exceptions below.\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[33m    The following exceptions were raised as we tried to load libtorchcodec:\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     80\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     81\u001b[39m )\n",
      "\u001b[31mRuntimeError\u001b[39m: Could not load libtorchcodec. Likely causes:\n          1. FFmpeg is not properly installed in your environment. We support\n             versions 4, 5, 6 and 7.\n          2. The PyTorch version (2.8.0+cu128) is not compatible with\n             this version of TorchCodec. Refer to the version compatibility\n             table:\n             https://github.com/pytorch/torchcodec?tab=readme-ov-file#installing-torchcodec.\n          3. Another runtime dependency; see exceptions below.\n        The following exceptions were raised as we tried to load libtorchcodec:\n        \n[start of libtorchcodec loading traceback]\nFFmpeg version 7: libavutil.so.59: cannot open shared object file: No such file or directory\nFFmpeg version 6: /lib/x86_64-linux-gnu/libpango-1.0.so.0: undefined symbol: g_once_init_leave_pointer\nFFmpeg version 5: libavutil.so.57: cannot open shared object file: No such file or directory\nFFmpeg version 4: libavutil.so.56: cannot open shared object file: No such file or directory\n[end of libtorchcodec loading traceback]."
     ]
    }
   ],
   "source": [
    "input_str = common_voice[\"train\"][0][\"sentence\"]\n",
    "labels = tokenizer(input_str).input_ids\n",
    "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input:                 {input_str}\")\n",
    "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
    "print(f\"Decoded w/out special: {decoded_str}\")\n",
    "print(f\"Are equal:             {input_str == decoded_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a87dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Indonesian\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19c6c8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['audio', 'sentence'],\n",
      "    num_rows: 4970\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(common_voice[\"train\"].with_format(\"numpy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e15bdd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000)) # Cast sampling rate yang awalnya 48000 menjadi 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2e7e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    '''\n",
    "    Fungsi ini melakukan praposes dataset, ingat bahwa ada dua komponen yang perlu dipraproses.\n",
    "    - input_features adalah array audio (stereo) yang akan diproses oleh feature_extractor untuk menjadi spektogram.\n",
    "    - labels adalah transkripsi yang akan diproses oleh tokenizer dengan menggunakan BPE untuk menjadi representasi numeriknya.\n",
    "    '''\n",
    "    audio = batch[\"audio\"]\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "\n",
    "    return batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
